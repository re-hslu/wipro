Im Projektauftrag unserer WIPRO wird definiert, dass wir mit dem «AI-First» Ansatz die Android APP angehen sollen. 
Damit wir das sinnvoll machen können und nicht für jede erdenkliche KI ein Abo abschliessen müssen, möchten wir die geeignetste KI evaluieren.
Wir haben uns dazu entschlossen die Evaluation zum einen aus wissenschaftlichen Daten aufzubauen und zum anderen das Selbstexperiment mit den Gratisversionen der einzelnen KI's zu machen.
Nachdem wir die einzelnen Tools evaluiert haben, werden wir uns für eines entscheiden und da dann auch die kostenpflichtige Version verwenden, 
um alle Features brauchen zu können und diesen «AI-First» Ansatz auch korrekt umsetzen zu können.

\subsection{Aufgabenstellung für die AI Tools}
Wir haben diversen KI Tools welche wir als gut empfinden, da wir sie bereits verwenden oder viel gutes gehört haben oder aufgrund der wissenschaftlichen Daten, 
die gleiche Aufgabe gestellt. Ziel war es dann, die erhaltenen Antworten zu prüfen und miteinander zu vergleichen um zumindest einen Anhaltspunkt zu erhalten, 
welches Tools die detaillierteste, aber auch für uns beste Analyse liefert.
Die vollständige Aufgabenstellung ist im Anhang dokumentiert (siehe Anhang~\ref{aufgabenstellung-ai-tools}).

\subsection{Auswertung}
Wir haben die folgenden KI-Tools evaluiert: ChatGPT, Grok (xAI), DeepSeek und Cursor. 
Jedes Tool hat die gleiche Aufgabenstellung erhalten und wurde auf seine Fähigkeiten zur Analyse und Unterstützung bei der Android-App-Entwicklung geprüft.

ChatGPT lieferte eine sehr gute Antwort mit vernünftiger Tiefe für eine erste Analyse. 
Die KI ist sehr stark bei Cross-Plattform-Wissen (iOS/Android, SwiftUI/Compose, Flutter, React Native) und bietet bewährte Architektur- und Testing-Hinweise. 
Die Pro-Version kostet 23 Euro pro Monat. Die vollständige Antwort von ChatGPT ist im Anhang dokumentiert (siehe Anhang~\ref{antwort-chatgpt}).

Grok von X hat ebenfalls eine gute Antwort gegeben, womit diverse gute Ansätze beschrieben sind und man eine gute Übersicht erhält, 
was gemacht werden muss und wie dies möglich sein kann. xAI hat mit „grok-code-fast-1" ein Modell für Entwickler-Aufgaben (Agentic Coding) vorgestellt, 
das Effizienz und Qualität in den Fokus stellt. Die SuperGrok-Version kostet 30 Euro pro Monat. Die vollständige Antwort von Grok ist im Anhang dokumentiert (siehe Anhang~\ref{antwort-grok}).

DeepSeek hat aus unserer Sicht sehr detailliert die Informationen aus der Aufgabenstellung und vor allem den Screenshots und dem Code gezogen. 
Dementsprechend wurden auch direkt Entwürfe für die Android App generiert und Strategien aufgezeigt. Nebst einer detaillierten Checkliste, 
was alles erledigt werden muss, gab es auch bereits einige Codebeispiele als Antwort. DeepSeek ist eine kostengünstige, 
vergleichbare Alternative mit der Möglichkeit zur Integration in IDE-Umgebungen. Die Nutzung ist kostenlos, es gibt keine Möglichkeit ein Abo abzuschliessen. 
Die vollständige Antwort von DeepSeek ist im Anhang dokumentiert (siehe Anhang~\ref{antwort-deepseek}).

Cursor ist nicht die gewöhnliche Web KI, sondern kann als Programm heruntergeladen werden und verwendet werden. 
Dabei kann ein gesamtes Projekt geöffnet werden und man kann da direkt zu einzelnen Dateien eine Frage stellen. 
Es gibt auch zum Beispiel ein Add On zu VS-Code. Für Android Studio gibt es ebenfalls Plugins. Cursor ist aber an sich keine KI sondern ein verbessertes Frontend, 
womit diverse Models geladen werden können. Durch das Frontend bietet es aber einem grossen Vorteil zu den direkten Models, 
da die KI den Kontext des gesamten Projekts hat um möglichst sinnvollen Code zu erstellen. Die Pro-Version kostet 20 Euro pro Monat. 
Die vollständige Antwort von Cursor ist im Anhang dokumentiert (siehe Anhang~\ref{antwort-cursor}).

\subsection{Vergleich}

\begin{table}[H]
  \centering
  \small % etwas kleinere Schrift für mehr Inhalt pro Zeile
  \setlength{\tabcolsep}{6pt} % Zellinnenabstand etwas kleiner
  \renewcommand{\arraystretch}{1.2} % Zeilenabstand angenehmer
  \begin{tabularx}{\textwidth}{lXXX}
    \toprule
    \textbf{KI} & \textbf{Stärken / beobachtete Fähigkeiten} & \textbf{Schwächen / Unsicherheiten} & \textbf{Eignung} \\
    \midrule
    Grok (xAI) &
    xAI hat mit „grok-code-fast-1" ein Modell für Entwickler-Aufgaben (Agentic Coding) vorgestellt; Effizienz/Qualität im Fokus; funktioniert auch als Backend in Tools wie Cursor. &
    Relativ jung; unklare Reife/Plattformtiefe; unklar, wie gut Apple/Android-SDKs abgedeckt sind. &
    Spannend mit aktueller Grok-Version; mit guter Prompt-Strategie evtl. starker Konkurrent zu Claude. \\
    \addlinespace
    DeepSeek &
    Kostengünstige, vergleichbare Alternative; Integration in IDE-Umgebungen möglich. &
    Weniger öffentlich dokumentierte Benchmarks; evtl. unreifer bei Edge-Cases / Plattformcode. &
    Gute Ergänzung, v. a. wenn Kosten zählen; für kritische Teile menschliches Review einplanen. \\
    \addlinespace
    ChatGPT &
    Sehr stark bei Cross-Plattform-Wissen (iOS/Android, SwiftUI/Compose, Flutter, RN); bewährt; gute Architektur- und Testing-Hinweise. &
    Token-Limits bei sehr grossen Codebasen (auer Enterprise/Pro); potenzielle Halluzinationen → Review nötig. &
    Top-Option neben Claude; stark für Architektur/Best Practices. \\
    \addlinespace
    Cursor &
    IDE-Frontend, das verschiedene Modelle einbindet; verbessert Workflow und Kontext im Editor. &
    Keine eigene KI; Leistung hängt vom gewählten Modell ab. &
    Als Interface/Workflow-Booster zusammen mit starkem Modell nutzen (z. B. Grok/ChatGPT/Claude). \\
    \bottomrule
  \end{tabularx}
  \caption{Auswertung der KI in Tabellenform}
\end{table}

\newpage
\subsection{Detaillierter Fragen zu Cursor}
Da wir von Cursor sehr begeistert sind, da es eine Applikation mit eigenem Frontend ist und wir ganze Ordnerstrukturen öffnen können (wie bei Visual Studio Code zum Beispiel), hat die KI direkt einen gesamten Überblick über die Codebasis.
Dadurch ist es einfacher an bessere Informationen zu gelangen, da der Kontext einzelner Codestellen für die KI immer klar ist, nicht wie bei herkömmlichen Online-Tools wo nur der wirklich hochgeladene Code vorhanden ist und da teilweise aber auch nicht korrekte Interpretationen gemacht werden.

Nachfolgend einige Screenshots welche an einem Beispiel zeigen wie gut eine Datei analysiert wird, da der Kontext vorhanden ist. 
Es wurde gefragt, was die Datei "CommonApplicationBaseModuleLoader.swift" macht und wie der Zusammenhang zum Rest de Projektes ist.
Hier sieht man sehr gut den Vorteil, da direkt die ganze Projektstruktur analysiert werden kann und so auch die Zusammenhänge besser klar sind für die KI. Zusätzlich werden auch relevante Codestellen hervorgehoben.

\begin{figure}[H]
  \centering
  \includegraphics[width=\textwidth]{Fotos/Cursor_1.png}
  \caption{Analysebeispiel in Cursor}
\end{figure}

\begin{figure}[H]
  \centering
  \includegraphics[width=\textwidth]{Fotos/Cursor_2.png}
  \caption{Analysebeispiel in Cursor}
\end{figure}

\begin{figure}[H]
  \centering
  \includegraphics[width=\textwidth]{Fotos/Cursor_3.png}
  \caption{Analysebeispiel in Cursor}
\end{figure}

\begin{figure}[H]
  \centering
  \includegraphics[width=\textwidth]{Fotos/Cursor_4.png}
  \caption{Analysebeispiel in Cursor}
\end{figure}

\newpage
\subsection{Fazit}
Nach all den Informationen welche wir gesammelt haben sind wir zum Schluss gekommen, dass wir mit Cursor und einer der oben aufgeführten KIs verwenden wollen.
Schlussendlich ist das wichtigste, dass die KI den Kontext des gesamten Projekts hat um möglichst sinnvollen Code zu erstellen und da hat Cursor klar den Vorteil.
Die eigentlichen LLMs sind im Grundsatz nicht gross anders. Wir haben beide ein ChatGPT Pro Abo, welches aber für Cursor nicht gilt, da über die OpenAPI die Calls gemacht werden und da nicht dieses Abo zählt.
Mit dem Cursor Pro Plan sollte man aber sehr gut fahren, vorallem wenn man den Auto-Modus eingeschaltet hat, da dann für kleinere Abfragen kostengünstige/kostenfreie APIs verwendet werden und nur für
grosse Abfragen werden kostenpflichtige APIs aufgerufen, womit der Pro Plan eigentlich gut reichen sollte. Trotzdem kann es sein, gerade wenn mehrere Personen daran arbeiten, dass dieser Plan nicht reicht und man am Ende mehr zahlen muss.

Nachdem wir die Analyse machten haben wir uns mit dem Dozenten kurz geschlossen und er hat sich bei der HSLU informiert, welche AI Tools sie begünstigen.
Daraus wurde dann klar, dass die HSLU sich für ChatGPT entschieden hat und uns somit die Entscheidung zum Teil abgenommen wurde.
Da wir aber trotzdem so gut Erfahrungen mit Cursor gemacht haben, wollten wir darauf nicht verzichten. Cursor kann so konfiguriert werden, 
dass es im Hintergrund eine API eines LLM verwendet, womit wir die Vorgabe ChatGPT einhalten konnten, in dem wir Cursor so konfiguriert haben, 
dass es nur mit der ChatGPT API kommuniziert. Somit konnten wir einen guten Kompromiss eingehen und hatten ein Tool womit ein ganzes Projekt (fast) im Kontext der Anfrage verfügbar ist.