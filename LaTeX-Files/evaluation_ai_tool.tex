Im Projektauftrag unserer WIPRO wird definiert, dass wir mit dem «AI-First» Ansatz die Android APP angehen sollen. 
Damit wir das sinnvoll machen können und nicht für jede erdenkliche KI ein Abo abschliessen müssen, möchten wir die geeignetste KI evaluieren.
Wir haben uns dazu entschlossen die Evaluation zum einen aus wissenschaftlichen Daten aufzubauen und zum anderen das Selbstexperiment mit den Gratisversionen der einzelnen KI's zu machen.
Nachdem wir die einzelnen Tools evaluiert haben, werden wir uns für eines entscheiden und da dann auch die kostenpflichtige Version verwenden, 
um alle Features brauchen zu können und diesen «AI-First» Ansatz auch korrekt umsetzen zu können.

\subsection{Aufgabenstellung für die AI Tools}
Wir haben diversen KI Tools welche wir als gut empfinden, da wir sie bereits verwenden oder viel gutes gehört haben oder aufgrund der wissenschaftlichen Daten, 
die gleiche Aufgabe gestellt. Ziel war es dann, die erhaltenen Antworten zu prüfen und miteinander zu vergleichen um zumindest einen Anhaltspunkt zu erhalten, 
welches Tools die detaillierteste, aber auch für uns beste Analyse liefert.
Die vollständige Aufgabenstellung ist im Anhang dokumentiert (siehe Anhang~\ref{aufgabenstellung-ai-tools}).

\subsection{Auswertung}
Wir haben die folgenden KI-Tools evaluiert: ChatGPT, Grok (xAI), DeepSeek und Cursor. 
Jedes Tool hat die gleiche Aufgabenstellung erhalten und wurde auf seine Fähigkeiten zur Analyse und Unterstützung bei der Android-App-Entwicklung geprüft.

ChatGPT lieferte eine sehr gute Antwort mit vernünftiger Tiefe für eine erste Analyse. 
Die KI ist sehr stark bei Cross-Plattform-Wissen (iOS/Android, SwiftUI/Compose, Flutter, React Native) und bietet bewährte Architektur- und Testing-Hinweise. 
Die Pro-Version kostet 23 Euro pro Monat. Die vollständige Antwort von ChatGPT ist im Anhang dokumentiert (siehe Anhang~\ref{antwort-chatgpt}).

Grok von X hat ebenfalls eine gute Antwort gegeben, womit diverse gute Ansätze beschrieben sind und man eine gute Übersicht erhält, 
was gemacht werden muss und wie dies möglich sein kann. xAI hat mit „grok-code-fast-1" ein Modell für Entwickler-Aufgaben (Agentic Coding) vorgestellt, 
das Effizienz und Qualität in den Fokus stellt. Die SuperGrok-Version kostet 30 Euro pro Monat. Die vollständige Antwort von Grok ist im Anhang dokumentiert (siehe Anhang~\ref{antwort-grok}).

DeepSeek hat aus unserer Sicht sehr detailliert die Informationen aus der Aufgabenstellung und vor allem den Screenshots und dem Code gezogen. 
Dementsprechend wurden auch direkt Entwürfe für die Android App generiert und Strategien aufgezeigt. Nebst einer detaillierten Checkliste, 
was alles erledigt werden muss, gab es auch bereits einige Codebeispiele als Antwort. DeepSeek ist eine kostengünstige, 
vergleichbare Alternative mit der Möglichkeit zur Integration in IDE-Umgebungen. Die Nutzung ist kostenlos, es gibt keine Möglichkeit ein Abo abzuschliessen. 
Die vollständige Antwort von DeepSeek ist im Anhang dokumentiert (siehe Anhang~\ref{antwort-deepseek}).

Cursor ist nicht die gewöhnliche Web KI, sondern kann als Programm heruntergeladen werden und verwendet werden. 
Dabei kann ein gesamtes Projekt geöffnet werden und man kann da direkt zu einzelnen Dateien eine Frage stellen. 
Es gibt auch zum Beispiel ein Add On zu VS-Code. Für Android Studio gibt es ebenfalls Plugins. Cursor ist aber an sich keine KI sondern ein verbessertes Frontend, 
womit diverse Models geladen werden können. Durch das Frontend bietet es aber einem grossen Vorteil zu den direkten Models, 
da die KI den Kontext des gesamten Projekts hat um möglichst sinnvollen Code zu erstellen. Die Pro-Version kostet 20 Euro pro Monat. 
Die vollständige Antwort von Cursor ist im Anhang dokumentiert (siehe Anhang~\ref{antwort-cursor}).

\subsection{Vergleich}

\begin{table}[H]
  \centering
  \small
  \setlength{\tabcolsep}{6pt}
  \renewcommand{\arraystretch}{1.2}
  \begin{tabularx}{\textwidth}{l>{\raggedright\arraybackslash}X>{\raggedright\arraybackslash}X>{\raggedright\arraybackslash}X}
    \toprule
    \textbf{KI} &
    \textbf{Stärken / beobachtete Fähigkeiten} &
    \textbf{Schwächen / Unsicherheiten} &
    \textbf{Eignung} \\
    \midrule
    Grok (xAI) &
    xAI hat mit „grok-code-fast-1“ ein Modell für Entwickler-Aufgaben (Agentic Coding) vorgestellt; Effizienz/Qualität im Fokus; funktioniert auch als Backend in Tools wie Cursor. &
    Relativ jung; unklare Reife/Plattformtiefe; unklar, wie gut Apple/Android-SDKs abgedeckt sind. &
    Spannend mit aktueller Grok-Version; mit guter Prompt-Strategie evtl. starker Konkurrent zu Claude. \\
    \addlinespace
    DeepSeek &
    Kostengünstige, vergleichbare Alternative; Integration in IDE-Umgebungen möglich. &
    Weniger öffentlich dokumentierte Benchmarks; evtl. unreifer bei Edge-Cases / Plattformcode. &
    Gute Ergänzung, v. a. wenn Kosten zählen; für kritische Teile menschliches Review einplanen. \\
    \addlinespace
    ChatGPT &
    Sehr stark bei Cross-Plattform-Wissen (iOS/Android, SwiftUI/Compose, Flutter, RN); bewährt; gute Architektur- und Testing-Hinweise. &
    Token-Limits bei sehr grossen Codebasen (außer Enterprise/Pro); potenzielle Halluzinationen → Review nötig. &
    Top-Option neben Claude; stark für Architektur/Best Practices. \\
    \addlinespace
    Cursor &
    IDE-Frontend, das verschiedene Modelle einbindet; verbessert Workflow und Kontext im Editor. &
    Keine eigene KI; Leistung hängt vom gewählten Modell ab. &
    Als Interface/Workflow-Booster zusammen mit starkem Modell nutzen (z. B. Grok/ChatGPT/Claude). \\
    \bottomrule
  \end{tabularx}
  \caption{Auswertung der KI in Tabellenform}
\end{table}

\subsection{Detaillierter Fragen zu Cursor}
Da wir von Cursor sehr begeistert sind, da es eine Applikation mit eigenem Frontend ist und wir ganze Ordnerstrukturen öffnen können (wie bei Visual Studio Code zum Beispiel), hat die KI direkt einen gesamten Überblick über die Codebasis.
Dadurch ist es einfacher an bessere Informationen zu gelangen, da der Kontext einzelner Codestellen für die KI immer klar ist, nicht wie bei herkömmlichen Online-Tools wo nur der wirklich hochgeladene Code vorhanden ist und da teilweise aber auch nicht korrekte Interpretationen gemacht werden.

Nachfolgend einige Screenshots welche an einem Beispiel zeigen wie gut eine Datei analysiert wird, da der Kontext vorhanden ist. 
Es wurde gefragt, was die Datei "CommonApplicationBaseModuleLoader.swift" macht und wie der Zusammenhang zum Rest des Projektes ist.
Hier sieht man sehr gut den Vorteil, da direkt die ganze Projektstruktur analysiert werden kann und so auch die Zusammenhänge besser klar sind für die KI. Zusätzlich werden auch relevante Codestellen hervorgehoben.

\begin{figure}[H]
  \centering
  \begin{subfigure}[b]{0.48\textwidth}
    \centering
    \includegraphics[width=\textwidth]{Fotos/Cursor_1.png}
    \caption{Analysebeispiel 1}
    \label{fig:cursor1}
  \end{subfigure}
  \hfill
  \begin{subfigure}[b]{0.48\textwidth}
    \centering
    \includegraphics[width=\textwidth]{Fotos/Cursor_2.png}
    \caption{Analysebeispiel 2}
    \label{fig:cursor2}
  \end{subfigure}
  \vspace{0.3em}
  \begin{subfigure}[b]{0.48\textwidth}
    \centering
    \includegraphics[width=\textwidth]{Fotos/Cursor_3.png}
    \caption{Analysebeispiel 3}
    \label{fig:cursor3}
  \end{subfigure}
  \hfill
  \begin{subfigure}[b]{0.48\textwidth}
    \centering
    \includegraphics[width=\textwidth]{Fotos/Cursor_4.png}
    \caption{Analysebeispiel 4}
    \label{fig:cursor4}
  \end{subfigure}
  \caption{Analysebeispiele in Cursor}
  \label{fig:cursor-examples}
  \vspace{-0.5em}
\end{figure}

\subsection{Fazit}
Nach all den Informationen welche wir gesammelt haben sind wir zum Schluss gekommen, dass wir mit Cursor und einer der oben aufgeführten KIs verwenden wollen.
Schlussendlich ist das wichtigste, dass die KI den Kontext des gesamten Projekts hat um möglichst sinnvollen Code zu erstellen und da hat Cursor klar den Vorteil.
Die eigentlichen LLMs sind im Grundsatz nicht gross anders. Wir haben beide ein ChatGPT Pro Abo, welches aber für Cursor nicht gilt, da über die OpenAPI die Calls gemacht werden und da nicht dieses Abo zählt.
Mit dem Cursor Pro Plan sollte man aber sehr gut fahren, vorallem wenn man den Auto-Modus eingeschaltet hat, da dann für kleinere Abfragen kostengünstige/kostenfreie APIs verwendet werden und nur für
grosse Abfragen werden kostenpflichtige APIs aufgerufen, womit der Pro Plan eigentlich gut reichen sollte. Trotzdem kann es sein, gerade wenn mehrere Personen daran arbeiten, dass dieser Plan nicht reicht und man am Ende mehr zahlen muss.

Nachdem wir die Analyse machten haben wir uns mit dem Dozenten kurz geschlossen und er hat sich bei der HSLU informiert, welche AI Tools sie begünstigen.
Daraus wurde dann klar, dass die HSLU sich für ChatGPT entschieden hat und uns somit die Entscheidung zum Teil abgenommen wurde.
Da wir aber trotzdem so gut Erfahrungen mit Cursor gemacht haben, wollten wir darauf nicht verzichten. Cursor kann so konfiguriert werden, 
dass es im Hintergrund eine API eines LLM verwendet, womit wir die Vorgabe ChatGPT einhalten konnten, in dem wir Cursor so konfiguriert haben, 
dass es nur mit der ChatGPT API kommuniziert. Somit konnten wir einen guten Kompromiss eingehen und hatten ein Tool womit ein ganzes Projekt (fast) im Kontext der Anfrage verfügbar ist.

\subsection{Erfahrungen mit AI-First Ansatz}

Während der gesamten Projektlaufzeit haben wir Cursor aktiv im Entwicklungsprozess eingesetzt und dabei sowohl positive als auch negative Erfahrungen gesammelt. 
Diese Erkenntnisse sind wertvoll für die zukünftige Nutzung von KI-Tools in Softwareentwicklungsprojekten.

\subsubsection*{Stärken von Cursor}

Einer der grössten Vorteile von Cursor war die Fehlersuche und Debugging-Unterstützung. 
Durch den vollständigen Projektkontext konnte Cursor Fehlerquellen schnell identifizieren und konkrete Lösungsvorschläge liefern. 
Besonders hilfreich war die Fähigkeit, Zusammenhänge zwischen verschiedenen Dateien und Modulen zu erkennen, 
was bei komplexen Architekturen wie unserer Multi-Feature- und Multi-Tenant-Struktur von grossem Wert war.

Ein weiteres herausragendes Anwendungsgebiet war das Portieren von iOS-Code nach Android. 
Da Cursor Zugriff auf beide Codebasen hatte, konnte es Swift-Code analysieren und entsprechende Kotlin-Äquivalente vorschlagen. 
Dies beschleunigte die Migration erheblich, insbesondere bei der Umsetzung der Common-Module, 
die eine 1:1-Übersetzung der iOS-Architektur erforderten. Cursor konnte dabei nicht nur syntaktische Unterschiede berücksichtigen, 
sondern auch plattformspezifische Besonderheiten wie die unterschiedliche Behandlung von Coroutines versus async/await in Swift erkennen.

Auch bei der Code-Analyse und Dokumentation war Cursor sehr nützlich. 
Komplexe Code-Stellen konnten schnell erklärt werden, und die Generierung von Kommentaren oder Dokumentation 
basierend auf dem vorhandenen Code funktionierte zuverlässig.

\subsubsection*{Grenzen und Herausforderungen}

Trotz der vielen Vorteile stiessen wir auch auf Bereiche, in denen Cursor weniger effektiv war. 
Besonders auffällig war dies bei UI-bezogenen Aufgaben. Die Generierung von Jetpack Compose UI-Komponenten war oft unzureichend, 
da die KI Schwierigkeiten hatte, das visuelle Design und die gewünschte Benutzererfahrung korrekt zu interpretieren. 
Die generierten UI-Komponenten entsprachen häufig nicht den Design-Anforderungen und mussten manuell überarbeitet werden, 
was den Zeitvorteil zunichtemachte.

Ähnliche Herausforderungen traten bei der Generierung kompletter Code-Strukturen auf. 
Während Cursor bei der Implementierung einzelner Funktionen oder Methoden sehr hilfreich war, 
scheiterte es oft bei der Erstellung grösserer Architektur-Komponenten. 
Die generierten Strukturen entsprachen nicht immer den etablierten Patterns und Konventionen unseres Projekts, 
und die notwendigen Anpassungen waren teilweise zeitaufwändiger als eine manuelle Implementierung.

Ein weiterer limitierender Faktor war die Abhängigkeit von der Qualität der Prompts. 
Um gute Ergebnisse zu erzielen, mussten sehr detaillierte und spezifische Anfragen formuliert werden, 
was teilweise mehr Zeit in Anspruch nahm als die direkte Code-Implementierung.

\subsubsection*{Fazit der praktischen Anwendung}

Insgesamt war Cursor ein wertvolles Werkzeug im Entwicklungsprozess, besonders für repetitive Aufgaben, 
Fehlersuche und Code-Migration. Für UI-Entwicklung und die Generierung komplexer Architekturen 
war der manuelle Ansatz jedoch oft effizienter. Der AI-First Ansatz hat sich somit als ergänzende, 
aber nicht ersetzende Methode erwiesen, die am besten in Kombination mit traditionellen Entwicklungsmethoden eingesetzt wird.