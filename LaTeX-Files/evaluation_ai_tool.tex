\section{Evaluation AI Tools}
Im Projektauftrag unserer WIPRO wird definiert, dass wir mit dem «AI-First» Ansatz die Android APP angehen sollen. 
Damit wir das sinnvoll machen können und nicht für jede erdenkliche KI ein Abo abschliessen müssen, möchten wir die geeignetste KI evaluieren.
Wir haben uns dazu entschlossen die Evaluation zum einen aus wissenschaftlichen Daten aufzubauen und zum anderen das Selbstexperiment mit den Gratisversionen der einzelnen KI’s zu machen.
Nachdem wir die einzelnen Tools evaluiert haben, werden wir uns für eines entscheiden und da dann auch die kostenpflichtige Version verwenden, 
um alle Features brauchen zu können und diesen «AI-First» Ansatz auch korrekt umsetzen können.


\subsection{Aufgabenstellung für die AI Tools}
Wir haben diversen KI Tools welche wir als gut empfinden, da wir sie bereits verwenden oder viel gutes gehört haben oder aufgrund der wissenschaftlichen Daten, 
die gleiche Aufgabe gestellt. Nachfolgend die Aufgabenstellung, welche wir den Tools gestellt haben:

\includepdf[pages=-]{Anhaenge/Aufgabenstellung_fuerAIs.pdf}

Ziel war es dann, die erhaltenen Antworten zu prüfen und miteinander zu vergleichen um zumindest einen Anhaltspunkt zu erhalten, 
welches Tools die detaillierteste, aber auch für uns beste Analyse liefert.

\subsection{Antworten}

\subsubsection{ChatGPT}
Die Antwort von ChatGPT zu der Fragenstellung ist sehr gut und in einer vernünftigen Tiefe für eine erste Analyse herausgekommen.
Preis: Pro Version 23Euro/month

Nachfolgend die Antwort von ChatGPT:

\includepdf[pages=-]{Anhaenge/Aufgabenstellung_Analyse_Vorgehen_CHATGPT.pdf}

\subsubsection{Grok}

Die KI von X hat ebenfalls eine Antwort gegeben, womit diverse gute Ansätze beschrieben sind und man eine gute Übersicht erhält, was gemacht werden muss und wie dies möglich sein kann.
Preis: SuperGrok 30/month

Nachfolgend die Antwort von Grok:

\includepdf[pages=-]{Anhaenge/Antwort_xAI_Grok.pdf}

\subsubsection{DeepSeek}

DeepSeek hat aus meiner Sicht sehr detailliert die Informationen aus der Aufgabenstellung und vor allem den Screenshots und dem Code gezogen. Dementsprechend wurden auch direkt Entwürfe für die Android App generiert und Strategien aufgezeigt. Nebst einer detaillierten Checkliste, was alles erledigt werden muss, gab es auch bereits einige Codebeispiele als Antwort. 
Preis: Free (bzw. keine Möglichkeit gefunden ein Abo abzuschliessen oder dafür zu zahlen wie bei den anderen)

Nachfolgend die Antwort von DeepSeek:

\includepdf[pages=-]{Anhaenge/deepseek_antwort.pdf}

\subsubsection{Cursor}

Die Antwort von Cursor ist aus meiner Sicht auch korrekt aber nicht gleich detailliert, kann aber denke ich durch gewisses Nachfragen immer noch eine grosse Hilfe für das Projekt sein.
Cursor ist nicht die gewöhnliche Web KI, sondern kann als Programm heruntergeladen werden und verwendet werden. Dabei kann ein gesamtes Projekt geöffnet werden und man kann da direkt zu einzelnen Dateien eine Frage stellen. Es gibt auch zum Beispiel ein Add On zu VS-Code. Für Android Studio gibt es ebenfalls Plugins.
Cursor ist aber an sich keine KI sondern ein verbessertes Frontend, womit diverse Models geladen werden können. Durch das frontend bietet es aber einem grossen Vorteil zu den direkten Models.
siehe auch: https://cursor.com/docs/models
Preis: Pro Version 20/month

Nachfolgend die Antwort von Cursor:

\includepdf[pages=-]{Anhaenge/cursor_antwort.pdf}

\subsection{Vergleich}

\begin{table}
  \caption{Auswertung der KI in Tabellenform}
  \centering
  \small % etwas kleinere Schrift für mehr Inhalt pro Zeile
  \setlength{\tabcolsep}{6pt} % Zellinnenabstand etwas kleiner
  \renewcommand{\arraystretch}{1.2} % Zeilenabstand angenehmer
  \begin{tabularx}{\textwidth}{lXXX}
    \toprule
    \textbf{KI} & \textbf{Stärken / beobachtete Fähigkeiten} & \textbf{Schwächen / Unsicherheiten} & \textbf{Eignung} \\
    \midrule
    Grok (xAI) &
    xAI hat mit „grok-code-fast-1“ ein Modell für Entwickler-Aufgaben (Agentic Coding) vorgestellt; Effizienz/Qualität im Fokus; funktioniert auch als Backend in Tools wie Cursor. &
    Relativ jung; unklare Reife/Plattformtiefe; unklar, wie gut Apple/Android-SDKs abgedeckt sind. &
    Spannend mit aktueller Grok-Version; mit guter Prompt-Strategie evtl. starker Konkurrent zu Claude. \\
    \addlinespace
    DeepSeek &
    Kostengünstige, vergleichbare Alternative; Integration in IDE-Umgebungen möglich. &
    Weniger öffentlich dokumentierte Benchmarks; evtl. unreifer bei Edge-Cases / Plattformcode. &
    Gute Ergänzung, v. a. wenn Kosten zählen; für kritische Teile menschliches Review einplanen. \\
    \addlinespace
    ChatGPT &
    Sehr stark bei Cross-Plattform-Wissen (iOS/Android, SwiftUI/Compose, Flutter, RN); bewährt; gute Architektur- und Testing-Hinweise. &
    Token-Limits bei sehr großen Codebasen (außer Enterprise/Pro); potenzielle Halluzinationen → Review nötig. &
    Top-Option neben Claude; stark für Architektur/Best Practices. \\
    \addlinespace
    Cursor &
    IDE-Frontend, das verschiedene Modelle einbindet; verbessert Workflow und Kontext im Editor. &
    Keine eigene KI; Leistung hängt vom gewählten Modell ab. &
    Als Interface/Workflow-Booster zusammen mit starkem Modell nutzen (z. B. Grok/ChatGPT/Claude). \\
    \bottomrule
  \end{tabularx}
\end{table}


\subsection{Detaillierter Fragen zu Cursor}
Da wir von Cursor sehr begeistert sind, da es eine Applikation mit eigenem Frontend ist und wir ganze Ordnerstrukturen öffnen können (wie bei Visual Studio Code zum Beispiel), hat die KI direkt einen gesamten Überblick über die Codebasis.
Dadurch ist es einfacher an bessere Informationen zu gelangen, da der Kontext einzelner Codestellen für die KI immer klar ist, nicht wie bei herkömmlichen Online-Tools wo nur der wirklich hochgeladene Code vorhanden ist und da teilweise aber auch nicht korrekte Interpretationen gemacht werden.

Nachfolgend einige Screenshots welche an einem Beispiel zeigen wie gut eine Datei analysiert wird, da der Kontext vorhanden ist. 
Es wurde gefragt, was die Datei "CommonApplicationBaseModuleLoader.swift" macht und wie der Zusammenhang zum Rest de Projektes ist:
Hier sieht man sehr gut den Vorteil, da direkt die ganze Projektstruktur analysiert werden kann und so auch die Zusammenhänge besser klar sind für die KI. Zusätzlich werden auch relevante Codestellen hervorgehoben.

\begin{figure}[h]
  \centering
  \includegraphics[width=\textwidth]{Fotos/Cursor_1.png}
  \caption{Analysebeispiel in Cursor}
\end{figure}

\begin{figure}[h]
  \centering
  \includegraphics[width=\textwidth]{Fotos/Cursor_2.png}
  \caption{Analysebeispiel in Cursor}
\end{figure}

\begin{figure}[h]
  \centering
  \includegraphics[width=\textwidth]{Fotos/Cursor_3.png}
  \caption{Analysebeispiel in Cursor}
\end{figure}

\begin{figure}[h]
  \centering
  \includegraphics[width=\textwidth]{Fotos/Cursor_4.png}
  \caption{Analysebeispiel in Cursor}
\end{figure}

\subsection{Fazit}
Nach all den Informationen welche wir gesammelt haben sind wir zum Schluss gekommen, dass wir mit Cursor und einer der oben aufgeführten KIs verwenden wollen.
Schlussendlich ist das wichtigste, dass die KI den Kontext des gesamten Projekts hat um möglichst sinnvollen Code zu erstellen und da hat Cursor klar den Vorteil.
Die eigentlichen LLMs sind im Grundsatz nicht gross anders. Wir haben beide ein ChatGPT Pro Abo, welches aber für Cursor nicht gilt, da über die OpenAPI die Calls gemacht werden und da nicht dieses Abo zählt.
Mit dem Cursor Pro Plan sollte man aber sehr gut fahren, vorallem wenn man den Auto-Modus eingeschaltet hat, da dann für kleinere Abfragen kostengünstige/kostenfreie APIs verwendet werden und nur für
grosse Abfragen werden kostenpflichtige APIs aufgerufen, womit der Pro Plan eigentlich gut reichen sollte. Trotzdem kann es sein, gerade wenn mehrere Personen daran arbeiten, dass dieser Plan nicht reicht und man am Ende mehr zahlen muss.